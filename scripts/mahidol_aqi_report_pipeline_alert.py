import json
import requests
import logging
from datetime import datetime, timedelta
from pathlib import Path
from bs4 import BeautifulSoup
import smtplib
from email.message import EmailMessage
import configparser

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.exceptions import AirflowSkipException

# ============ CONFIG ============ #
BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
HTML_FILE = DATA_DIR / "mahidol_aqi.html"
OUTPUT_FILE = DATA_DIR / "tmp_mahidol.json"
DATA_DIR.mkdir(parents=True, exist_ok=True)

LATITUDE = 13.794606
LONGITUDE = 100.327256
DESCRIPTION = "‡∏Ñ‡∏ì‡∏∞‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏°‡∏´‡∏¥‡∏î‡∏•"
COUNTRY = "Thailand"
STATE = "Nakhon Pathom"
CITY = "Salaya"

# ============ FUNCTIONS ============ #
def get_cursor():
    hook = PostgresHook(postgres_conn_id="postgres_conn")
    conn = hook.get_conn()
    return conn, conn.cursor()

def is_data_in_db(date_time_str):
    conn, cursor = get_cursor()
    try:
        cursor.execute("""
            SELECT 1 FROM factmahidolaqitable
            WHERE date_time = %s
            LIMIT 1
        """, (date_time_str,))
        return cursor.fetchone() is not None
    finally:
        cursor.close()
        conn.close()

# --- ====== TASK 1 ====== ---
def get_data_mahidol_aqi_report():
    URL = "https://mahidol.ac.th/aqireport/"
    try:
        res = requests.get(URL, timeout=10)
        res.raise_for_status()
        tmp_path = Path(str(HTML_FILE) + ".tmp")
        with open(tmp_path, 'w', encoding='utf-8') as f:
            f.write(res.text)
        tmp_path.rename(HTML_FILE)
        logging.info("Saved Mahidol AQI HTML successfully.")

    except Exception as e:
        logging.error(f"Failed to fetch Mahidol AQI report: {e}")
        raise

def get_clean_text(element_id, soup: BeautifulSoup):
    element = soup.find(id=element_id)
    if element:
        return element.get_text(strip=True, separator=" ").split()[0].strip()
    return None

def convert_to_datetime(datetime_str):
    if datetime_str:
        try:
            return datetime.strptime(datetime_str, "%d %B %Y, %H:%M hrs.")
        except ValueError as e:
            logging.error(f"Error parsing datetime: {e}")
    return None

def get_main_pollution_text(soup: BeautifulSoup):
    try:
        aqi_container = soup.find("div", class_="fa-10x")
        if aqi_container:
            h4_element = aqi_container.find("h4")
            if h4_element:
                return h4_element.get_text(strip=True).replace("(", "").replace(")", "").strip()
    except Exception as e:
        logging.error(f"Error in get_main_pollution_text: {e}")
    return None

# --- ====== TASK 2 ====== ---
def create_json_object():
    try:
        with open(HTML_FILE, "r", encoding="utf-8") as file:
            soup = BeautifulSoup(file, "html.parser")
    except Exception as e:
        logging.error(f"Error reading HTML file: {e}")
        raise

    try:
        date_en = soup.find(id="ContentPlaceHolder1_lblDateTimeEN")
        datetime_value = f" {date_en.get_text(strip=True)}".strip() if date_en else None
        datetime_value_obj = convert_to_datetime(datetime_value)

        air_quality_div = soup.find("div", class_="alert")
        air_quality_text = air_quality_div.find("h4").get_text(strip=True) if air_quality_div else None
        main_pollution = get_main_pollution_text(soup)

        data = {
            "Datetime": datetime_value_obj.isoformat() if datetime_value_obj else None,
            "Air Quality": air_quality_text,
            "Main Pollution": main_pollution,
            "AQI": get_clean_text("ContentPlaceHolder1_lblAQI", soup),
            "PM25": get_clean_text("ContentPlaceHolder1_lblHourlyPM25", soup),
            "PM10": get_clean_text("ContentPlaceHolder1_lblHourlyPM10", soup),
            "O3": get_clean_text("ContentPlaceHolder1_lblHourlyO3", soup),
            "CO": get_clean_text("ContentPlaceHolder1_lblHourlyCO", soup),
            "NO2": get_clean_text("ContentPlaceHolder1_lblHourlyNO2", soup),
            "SO2": get_clean_text("ContentPlaceHolder1_lblHourlySO2", soup),
            "Temperature": get_clean_text("ContentPlaceHolder1_lblTemperature", soup),
            "Humidity": get_clean_text("ContentPlaceHolder1_lblHumidity", soup),
            "Wind Speed": get_clean_text("ContentPlaceHolder1_lblWindSpeed", soup),
            "Wind Direction": get_clean_text("ContentPlaceHolder1_lblWindDirection", soup),
            "Rainfall": get_clean_text("ContentPlaceHolder1_lblRainfall", soup),
            "Solar Radiation": get_clean_text("ContentPlaceHolder1_lblSolar", soup),
        }
        logging.info("Extracted data: %s", data)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö datetime ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        iso_string = data["Datetime"] #FORMAT eg. "2025-04-02T21:00:00"
        if iso_string:
            dt_obj = datetime.strptime(iso_string, "%Y-%m-%dT%H:%M:%S")
            current_dt_str = dt_obj.strftime("%Y-%m-%d %H:%M")
        else:
            raise Exception(f"Data DateTime has Error value of Error: {current_dt_str}")
        
        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Database ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ datetime ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        data_time_now_obj = datetime.now()+ timedelta(hours=7)
        data_time_now_str = data_time_now_obj.strftime("%Y-%m-%d %H:00") 
        if is_data_in_db(data_time_now_str):
            raise AirflowSkipException(f"Data for {data_time_now_str} already exists in DB. Skipping DAG.")

        # ‡πÇ‡∏´‡∏•‡∏î datetime ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
        if OUTPUT_FILE.exists():
            with open(OUTPUT_FILE, "r", encoding="utf-8") as f_check:
                prev_data = json.load(f_check)
            prev_dt_str = prev_data["Datetime"]
            prev_dt_obj = datetime.strptime(prev_dt_str, "%Y-%m-%dT%H:%M:%S")
            prev_dt_str = prev_dt_obj.strftime("%Y-%m-%d %H:%M")
            if current_dt_str == prev_dt_str and is_data_in_db(prev_dt_str):
                raise Exception(f"Data has not been updated yet: {current_dt_str} == {prev_dt_str}")

        # ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£ "Atomic File Write":
        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß (.tmp) ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ rename ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÉ‡∏ô Task ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        tmp_path = Path(str(OUTPUT_FILE) + ".tmp")
        with open(tmp_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        tmp_path.rename(OUTPUT_FILE)
        logging.info("Response saved successfully.")

    except Exception as e:
        logging.error(f"Error create_json_object: {e}")
        raise

# --- ====== TASK 3 ====== ---
def load_mahidol_aqi_to_postgres():
    logging.info("Starting load_mahidolAQI_to_postgres")
    conn, cursor = get_cursor()
    try:
        # Load pollution mapping from config
        with open('/opt/airflow/config/mapping_main_pollution.json', 'r', encoding='utf-8') as mf:
            pollution_mapping = json.load(mf)

        # Load raw JSON data
        with open('/opt/airflow/data/tmp_mahidol.json', 'r', encoding='utf-8') as f:
            raw_data: dict = json.load(f)

        date_time_str = raw_data["Datetime"]
        date_time_obj = datetime.strptime(date_time_str, "%Y-%m-%dT%H:%M:%S")
        date_str = date_time_obj.strftime("%Y-%m-%d")
        time_str = date_time_obj.strftime("%H:%M:%S")

        # --- Step 1: Insert into dimDateTimeTable (if not exists) ---
        cursor.execute("""
            INSERT INTO dimDateTimeTable (date_time, date, time, day, month, year, hour)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (date_time) DO NOTHING;
        """, (
            date_time_obj,
            date_str,
            time_str,
            date_time_obj.day,
            date_time_obj.month,
            date_time_obj.year,
            date_time_obj.hour
        ))

        # --- Step 2: Insert into dimLocationTable (if not exists) ---
        cursor.execute("""
            SELECT description, location_id FROM dimLocationTable
            WHERE description = %s;
        """, (DESCRIPTION,))
        result = cursor.fetchone()
        print(f"fecth cursor result find location id: {result}")
        if result:
            location_id = result[1]
        else:
            cursor.execute("""
                INSERT INTO dimLocationTable (latitude, longitude, description, country, state, city)
                VALUES (%s, %s, %s, %s, %s, %s)
                RETURNING location_id;
            """, (LATITUDE, LONGITUDE, DESCRIPTION, COUNTRY, STATE, CITY))
            location_id = cursor.fetchone()[0]

        # --- Step 3: Insert into dimMainPollutionTable (if not exists) ---
        main_code = raw_data["Main Pollution"]
        if main_code not in pollution_mapping:
            logging.warning(f"Pollution code '{main_code}' not found in mapping file.")
        mapping = pollution_mapping.get(main_code, {"unit": "unknown", "name_pollution": main_code})
        cursor.execute("""
            INSERT INTO dimMainPollutionTable (main_pollution_code, unit, name_pollution)
            VALUES (%s, %s, %s)
            ON CONFLICT (main_pollution_code) DO NOTHING;
        """, (main_code, mapping['unit'], mapping['name_pollution']))

        # --- Step 4: Insert into factMahidolAqiTable ---
        def clean_value(val):
            try:
                return round(float(val), 2)
            except:
                return None

        cursor.execute("""
            INSERT INTO factmahidolaqitable (
                date_time, location_id, main_pollution_code,
                air_quality_text, aqi,
                pm25_value, pm10_value, o3_value,
                co_value, no2_value, so2_value,
                temperature_c, humidity, wind_speed,
                wind_direction, rainfall, solar_radiation
            )
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (date_time, location_id, main_pollution_code) DO NOTHING;
        """, (
            date_time_obj,
            location_id,
            main_code,
            raw_data.get("Air Quality"),
            clean_value(raw_data.get("AQI")),
            clean_value(raw_data.get("PM25")),
            clean_value(raw_data.get("PM10")),
            clean_value(raw_data.get("O3")),
            clean_value(raw_data.get("CO")),
            clean_value(raw_data.get("NO2")),
            clean_value(raw_data.get("SO2")),
            clean_value(raw_data.get("Temperature")),
            clean_value(raw_data.get("Humidity")),
            clean_value(raw_data.get("Wind Speed")),
            clean_value(raw_data.get("Wind Direction")),
            clean_value(raw_data.get("Rainfall")),
            clean_value(raw_data.get("Solar Radiation"))
        ))
        conn.commit()
        logging.info("Finished load_mahidolAQI_to_postgres")

    except Exception as e:
        conn.rollback()
        logging.error(f"Error during ETL: {e}")
        raise

    finally:
        cursor.close()
        conn.close()
        logging.info("ETL to PostgreSQL Completed")

# --- ====== TASK 4 ====== ---
def alert_email():
    def email_alert(subject: str, body: str, to: str):
        msg = EmailMessage()
        msg.set_content(body)
        msg["Subject"] = subject
        msg["To"] = to

        user = "supakorn.ming@gmail.com"  # Sender Email
        msg["From"] = user

        config_path = BASE_DIR / "config" / "config.conf"
        config = configparser.ConfigParser()
        config.read(config_path)
        password = config.get("email", "password")
        logging.info(f"Sending email from {user} to {to} using config {config_path}")

        try:
            with smtplib.SMTP("smtp.gmail.com", 587) as server:
                server.starttls()
                server.login(user, password)
                server.send_message(msg)
                logging.info(f"Email sent to {to}")
        except Exception as e:
            logging.error(f"Failed to send email to {to}: {e}")
            raise

    def clean_value(val):
        try:
            return round(float(val), 2)
        except (TypeError, ValueError):
            return None

    try:
        with open(DATA_DIR / "tmp_mahidol.json", 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
    except Exception as e:
        logging.error(f"Error loading AQI JSON data: {e}")
        raise

    aqi_value = clean_value(raw_data.get("AQI"))
    body = None

    if aqi_value is not None:
        if 0 <= aqi_value <= 50:
            logging.info(f"AQI is safe ({aqi_value}). No alert needed.")
            raise AirflowSkipException("AQI in safe range. Skipping alert.")
        elif 51 <= aqi_value <= 100:
            logging.info(f"AQI is ({aqi_value}) alert. 51 <= aqi_value <= 100")
            body = (
                f"‡∏Ñ‡πà‡∏≤ AQI ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô {aqi_value}\n"
                "‚ö†Ô∏è AQI ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á (51-100)\n"
                "‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥\n"
                "‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏£‡∏Ñ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏Ñ‡∏ß‡∏£‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏≠‡∏≤‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏≠ ‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏•‡∏≥‡∏ö‡∏≤‡∏Å ‡∏£‡∏∞‡∏Ñ‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏∑‡∏≠‡∏á‡∏ï‡∏≤"
            )
        elif 101 <= aqi_value <= 200:
            logging.info(f"AQI is ({aqi_value}) alert. 101 <= aqi_value <= 200")
            body = (
                f"‡∏Ñ‡πà‡∏≤ AQI ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô {aqi_value}\n"
                "‚ö†Ô∏è AQI ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û (101-200)\n"
                "‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ñ‡∏ß‡∏£‡∏•‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å\n"
                "‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏£‡∏Ñ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å ‡πÅ‡∏•‡∏∞‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥"
            )
        elif aqi_value > 200:
            logging.info(f"AQI is ({aqi_value}) alert. aqi_value > 200")
            body = (
                f"‡∏Ñ‡πà‡∏≤ AQI ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô {aqi_value}\n"
                "üö® AQI ‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 200)\n"
                "‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á‡∏ó‡∏∏‡∏Å‡∏ä‡∏ô‡∏¥‡∏î ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏ô‡πÄ‡∏≠‡∏á\n"
                "‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏£‡∏£‡∏µ‡∏ö‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ó‡∏±‡∏ô‡∏ó‡∏µ"
            )
        else:
            logging.warning(f"AQI has unexpected value: {aqi_value}")
    else:
        logging.warning("AQI value not found in data.")
        raise AirflowSkipException("No AQI value to evaluate.")

    users_file = BASE_DIR / "config" / "pm25_alert_emails.txt"
    try:
        with open(users_file, "r", encoding="utf-8") as file:
            recipients = [line.strip() for line in file if line.strip()]
    except Exception as e:
        logging.error(f"Could not load email list: {e}")
        raise

    if not recipients:
        logging.warning("No recipients found in email list. Skipping alert.")
        raise AirflowSkipException("No recipients to send to.")

    for email in recipients:
        email_alert(subject="PM2.5 Alert Notification", body=body, to=email)

    logging.info("All alert emails sent successfully.")

# ============ DAG ============ #
default_args = {
    'owner': 'Polakorn Anantapakorn Ming',
    'start_date': datetime(2025, 3, 20),
}

with DAG(
    dag_id='mahidol_aqi_pipeline_v2_alert_1',
    # schedule_interval='30 * * * *',
    schedule_interval=None,
    default_args=default_args,
    description='A simple data pipeline for Mahidol AQI report',
    catchup=False,
) as dag:

    # t1 = PythonOperator(
    #     task_id='scraping_mahidol_aqi_report',
    #     python_callable=get_data_mahidol_aqi_report
    # )

    # t2 = PythonOperator(
    #     task_id='create_json_mahidol_aqi',
    #     python_callable=create_json_object
    # )

    # t3 = PythonOperator(
    #     task_id='load_data_mahidolAQI_to_postgresql',
    #     python_callable=load_mahidol_aqi_to_postgres
    # )

    t4 = PythonOperator(
        task_id='alert_email',
        python_callable=alert_email
    )

    # t1 >> t2 >> [t3, t4]
    t4
